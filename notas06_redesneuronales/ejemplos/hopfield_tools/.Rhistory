pos.prediction <- predict(NBA.SOM3, newdata = as.factor(NBA.testing))
NBA.testing$data
NBA.training <- scale(NBA[training_indices, NBA.measures2])
NBA.testing <- scale(NBA[-training_indices, NBA.measures2],
center = attr(NBA.training, "scaled:center"),
scale = attr(NBA.training, "scaled:scale"))
NBA.SOM3 <- xyf(NBA.training, classvec2classmat(NBA$Pos[training_indices]),
grid = somgrid(13, 13, "hexagonal"),rlen = 100)
pos.prediction <- predict(NBA.SOM3, newdata = (NBA.testing))
w1 = seq(-10,10,length=50)
w2 = w1
(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(0 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2
# Definimos la función que dibujaremos
f1 = function(w1,w2)
{(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(0 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2}
# La función outer evalua la función f en cada
z = outer(w1,w2,f1)
#z = f(x, y)
persp(w1,w2,z, theta = 30, phi = 30, expand = 0.5, col = "lightblue")
f2 = function(w1,w2)
{(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(1 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2}
# La función outer evalua la función f en cada
z = outer(w1,w2,f2)
persp(w1,w2,z, theta = 30, phi = 30, expand = 0.5, col = "lightblue")
fopt1 <- function(x)
{
w1 <- x[1]
w2 <- x[2]
(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(0 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2
}
optim(c(0,0), fopt1)
fopt2 <- function(x)
{
w1 <- x[1]
w2 <- x[2]
(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(1 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2
}
optim(c(0,0), fopt2)
fopt1 <- function(x)
{
w1 <- x[1]
w2 <- x[2]
w0 <- x[3]
(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(0 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2
}
optim(c(0,0,0), fopt1)
fopt2 <- function(x)
{
w1 <- x[1]
w2 <- x[2]
w0 <- x[3]
(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(1 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2
}
optim(c(0,0,0), fopt2)
help(optim)
optim(c(0,0,0), fopt2)
w1 = seq(-1,1,length=50)
w2 = w1
f1 = function(w1,w2)
{(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(0 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2}
# La función outer evalua la función f en cada
z = outer(w1,w2,f1)
#z = f(x, y)
# Un gráfico en perspectiva
persp(w1,w2,z, theta = 30, phi = 30, expand = 0.5, col = "lightblue")
f2 = function(w1,w2)
{(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(1 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2}
# La función outer evalua la función f en cada
z = outer(w1,w2,f2)
#z = f(x, y)
# Un gráfico en perspectiva
persp(w1,w2,z, theta = 30, phi = 30, expand = 0.5, col = "lightblue")
fopt1 <- function(x)
{
w1 <- x[1]
w2 <- x[2]
(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(0 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2
}
optim(c(0,0), fopt1)
w1 = seq(0,0.5,length=50)
w2 = w1
#Punto 1 (3; 2; 1)
#Punto 2 (1; 4; 1)
#Punto 3 (-1; 1; 0)
#Punto 4 (-1; -1; 0)
#Punto 5 (2; -1; 0)
# Definimos la función que dibujaremos
f1 = function(w1,w2)
{(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(0 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2}
# La función outer evalua la función f en cada
z = outer(w1,w2,f1)
#z = f(x, y)
# Un gráfico en perspectiva
persp(w1,w2,z, theta = 30, phi = 30, expand = 0.5, col = "lightblue")
f2 = function(w1,w2)
{(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(1 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2}
# La función outer evalua la función f en cada
z = outer(w1,w2,f2)
#z = f(x, y)
# Un gráfico en perspectiva
persp(w1,w2,z, theta = 30, phi = 30, expand = 0.5, col = "lightblue")
fopt1 <- function(x)
{
w1 <- x[1]
w2 <- x[2]
(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(0 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2
}
optim(c(0,0), fopt1)
fopt2 <- function(x)
{
w1 <- x[1]
w2 <- x[2]
(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(1 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2
}
optim(c(0,0), fopt2)
fopt1 <- function(x)
{
w1 <- x[1]
w2 <- x[2]
w0 <- x[3]
(1 - (2*w1 + w2*3))^2+ (1 -(w1 + w2*4))^2 + (0 - ((-1)*w1 + w2))^2 +
(0 - ((-1)*w1 + (-1)*w2))^2 + (0 - (2*w1 + (-1)*w2))^2
}
optim(c(0,0,0), fopt1)
w1 = seq(-10,10,length=50)
w2 = w1
#Punto 1 (3; 2; 1)
#Punto 2 (1; 4; 1)
#Punto 3 (-1; 1; 0)
#Punto 4 (-1; -1; 0)
#Punto 5 (2; -1; 0)
# Definimos la función que dibujaremos
f1 = function(w1,w2)
{(1 - 1/(1+exp(2*w1 + w2*3)))^2+ (1 - 1/(1+exp(w1 + w2*4)))^2 + (0 - 1/(1+exp((-1)*w1 + w2)))^2 +
(0 - 1/(1+exp((-1)*w1 + (-1)*w2)))^2 + (0 - 1/(1+exp(2*w1 + (-1)*w2)))^2}
z = outer(w1,w2,f1)
persp(w1,w2,z, theta = 30, phi = 30, expand = 0.5, col = "lightblue")
f2 = function(w1,w2)
{(1 - 1/(1+exp(2*w1 + w2*3)))^2+ (1 - 1/(1+exp(w1 + w2*4)))^2 + (0 - 1/(1+exp((-1)*w1 + w2)))^2 +
(1 - 1/(1+exp((-1)*w1 + (-1)*w2)))^2 + (0 - 1/(1+exp(2*w1 + (-1)*w2)))^2}
# La función outer evalua la función f en cada
z = outer(w1,w2,f2)
persp(w1,w2,z, theta = 30, phi = 30, expand = 0.5, col = "lightblue")
#Preparación de los datos
input1 = c(1,1,0,0)
input2 = c(1,0,1,0)
outputAND = c(1,0,0,0)
outputOR = c(1,1,1,0)
outputXOR = c(0,1,1,0)
inputs = cbind(input1, input2)
datos1 = cbind(input1,input2,outputAND)
datos2 = cbind(input1,input2,outputOR)
datos3 = cbind(input1,input2,outputXOR)
library(neuralnet)
library(nnet)
matriz1 <- matrix(nrow = 4, ncol = 100)
for (i in 1:100){
set.seed(i)
#matriz1[,i] = as.vector(nnet(inputs,outputXOR,data=data1,size=2,linout=T)$fitted.values)
modelo3 <- neuralnet(outputXOR ~ input1 + input2, hidden =2, data = datos3)
matriz1[,i] = as.vector(prediction(modelo3)$rep[,3])
}
matriz1
plot(modelo3)
library(clusterGeneration)
seed.val<-2
set.seed(seed.val)
num.vars<-8
num.obs<-1000
#input variables
cov.mat<-genPositiveDefMat(num.vars,covMethod=c("unifcorrmat"))$Sigma
rand.vars<-mvrnorm(num.obs,rep(0,num.vars),Sigma=cov.mat)
library(clusterGeneration)
install.packages("clusterGeneration")
library(clusterGeneration)
seed.val<-2
set.seed(seed.val)
num.vars<-8
num.obs<-1000
cov.mat<-genPositiveDefMat(num.vars,covMethod=c("unifcorrmat"))$Sigma
rand.vars<-mvrnorm(num.obs,rep(0,num.vars),Sigma=cov.mat)
parms<-runif(num.vars,-10,10)
y1<-rand.vars %*% matrix(parms) + rnorm(num.obs,sd=20)
parms2<-runif(num.vars,-10,10)
y2<-rand.vars %*% matrix(parms2) + rnorm(num.obs,sd=20)
rand.vars<-data.frame(rand.vars)
resp<-data.frame(y1,y2)
names(resp)<-c('Y1','Y2')
dat.in<-data.frame(resp,rand.vars)
head(dat.in)
library(nnet)
set.seed(seed.val)
mod1<-nnet(rand.vars,resp,data=dat.in,size=10,linout=T)
library(neuralnet)
form.in<-as.formula('Y2~X1+X2+X3+X4+X5+X6+X7+X8')
set.seed(seed.val)
mod2<-neuralnet(form.in, data=dat.in, hidden=10, stepmax = 100)
library(RSNNS)
set.seed(seed.val)
mod3<-mlp(rand.vars, resp, size=10,linOut=T)
library(reshape)
library(scales)
install.packages("reshape")
library(reshape)
library(scales)
set.seed(500)
library(MASS)
data <- Boston
#Eliminación de missing (si los hubiera, se observa que no hay)
apply(data,2,function(x) sum(is.na(x)))
index <- sample(1:nrow(data),round(0.75*nrow(data)))
train <- data[index,]
test <- data[-index,]
lm.fit <- glm(medv~., data=train)
summary(lm.fit)
pr.lm <- predict(lm.fit,test)
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
train_ <- scaled[index,]
test_ <- scaled[-index,]
library(neuralnet)
n <- names(train_)
f <- as.formula(paste("medv ~", paste(n[!n %in% "medv"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=c(5,3),linear.output=T)
plot(nn)
pr.nn <- compute(nn,test_[,1:13])
pr.nn_ <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (test_$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn
print(paste(MSE.lm,MSE.nn))
par(mfrow=c(1,2))
plot(test$medv,pr.nn_,col='red',main='Real vs predicted NN',pch=18,cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend='NN',pch=18,col='red', bty='n')
plot(test$medv,pr.lm,col='blue',main='Real vs predicted lm',pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend='LM',pch=18,col='blue', bty='n', cex=.95)
library(boot)
set.seed(200)
lm.fit <- glm(medv~.,data=data)
cv.glm(data,lm.fit,K=10)$delta[1]
set.seed(450)
cv.error <- NULL
k <- 10
library(plyr)
pbar <- create_progress_bar('text')
pbar$init(k)
for(i in 1:k){
index <- sample(1:nrow(data),round(0.9*nrow(data)))
train.cv <- scaled[index,]
test.cv <- scaled[-index,]
nn <- neuralnet(f,data=train.cv,hidden=c(5,2),linear.output=T)
pr.nn <- compute(nn,test.cv[,1:13])
pr.nn <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.cv.r <- (test.cv$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
cv.error[i] <- sum((test.cv.r - pr.nn)^2)/nrow(test.cv)
pbar$step()
}
mean(cv.error)
cv.error
library(rgl)
install.packages("rgl")
library(rgl)
Random.Unit <-function(n, dim, threshold) {
points <- runif(n * dim)
points <- matrix(points, ncol = dim)
label <- ifelse(apply(points, 1, sum) < threshold, -1, 1)
return(cbind(label, x0 = rep(1, n), points))
}
Classify <- function(x, weights) {
return(sign(x %*% weights))
}
# Perceptron is a simple implementation of the perceptron learning algorithm.
# It accepts data of the form data[1] = label, data[2] = x_0 = 1, data[3] = x_1,
# etc. w0 is initilized to -threshold and the weights returned are such that
# sign(w_0 * x_0 + w_1 * x_1 + ... + w_n * x_n) == label
Perceptron <- function(data, threshold) {
w <- c(-threshold, runif(ncol(data) - 2))
n <- nrow(data)
label <- data[ , 1]
obs <- data[ , 2:ncol(data)]
misclassfied <- TRUE
while (misclassfied) {
misclassfied <- FALSE
for (i in 1:n) {
if (label[i] * Classify(obs[i , ], w) <= 0) {
w <- w + label[i] * obs[i , ]
misclassfied <- TRUE
}
}
}
return(w)
}
Plot2D <- function(points, a, b) {
plot(points[, 3:4], xlab = "X", ylab = "Y",
pch = ifelse(points[, 1] == 1, 2, 8),
col = ifelse(points[, 1] == 1, "blue", "red"))
abline(a, b)
}
THRESHOLD <- .5
pts <- Random.Unit(1000, 2, THRESHOLD)
Plot2D(pts, THRESHOLD, -1)
w <- Perceptron(pts, THRESHOLD)
Plot2D(pts, -w[1]/w[3], -w[2]/ w[3])
w <- Perceptron(pts, THRESHOLD)
Plot2D(pts, -w[1]/w[3], -w[2]/ w[3])
w
pts <- Random.Unit(1000, 2, THRESHOLD)
Plot2D(pts, THRESHOLD, -1)
pts
-w[1]/w[3]
-w[2]/ w[3]
points[, 3:4]
-w[2]/ w[3]
Plot2D(pts, THRESHOLD, -1)
THRESHOLD
-1
-w[2]/ w[3]
-w[1]/w[3]
set.seed(1)
clientes=20000
saldo_vista=runif(clientes,0,1)*10000
saldo_ppi=(runif(clientes,0.1,0.2)*rpois(clientes,1))*100000
saldo_fondos=(runif(clientes,0.1,0.9)*(rpois(clientes,1)-1>0))*100000
edad=rpois(clientes,60)
datos_ini<-data.frame(cbind(saldo_vista,saldo_ppi,saldo_fondos,edad))
datos_ini$saldo_ppi=(edad<=68)*datos_ini$saldo_ppi
set.seed(2)
datos_ini$potencial=runif(1,0,1)+
(log(edad)/(log(68))/100) +
runif(1,0,0.001)*(saldo_vista>5000)+
runif(1,0,0.001)*(saldo_fondos>10000)+
runif(1,0,0.007)*(saldo_ppi>10000)-
runif(1,0,0.2)
datos_ini$pvi=as.factor((datos_ini$potencial>=quantile(datos_ini$potencial, 0.90))*1)
head(datos_ini)
pred=cbind(datos_ini$saldo_vista,datos_ini$saldo_ppi,
datos_ini$saldo_fondos,datos_ini$edad)
head(pred)
target=as.matrix(datos_ini$pvi)
select=sample(1:clientes,clientes*0.9)
library(nnet)
set.seed(10)
redn=nnet(pred[select,],as.numeric(target[select,]), size = 2,
rang =0.1,decay = 5e-4, maxit = 500)
pred[select,]
prediccion=predict(redn, datos_ini)
names(prediccion)=c("prediccion")
datos_ini.pred=cbind(datos_ini,prediccion)
summary(datos_ini.pred)
media <- tapply(datos_ini.pred$prediccion, list(pvi=datos_ini.pred$pvi), mean, na.rm=TRUE)
varianza <- tapply(datos_ini.pred$prediccion, list(pvi=datos_ini.pred$pvi), var, na.rm=TRUE)
media
varianza^0.5
varianza^0.5/media
datos_ini.test = datos_ini.pred[-select,]
library(reshape)
datos_ini.test=sort_df(datos_ini.test,vars='prediccion')
media <- tapply(datos_ini.test$prediccion, list(pvi=datos_ini.test$pvi), mean)
varianza <- tapply(datos_ini.test$prediccion, list(pvi=datos_ini.test$pvi), var)
media
varianza^0.5
varianza^0.5/media
set.seed(1)
clientes=20000
saldo_vista=runif(clientes,0,1)*10000
saldo_ppi=(runif(clientes,0.1,0.2)*rpois(clientes,1))*100000
saldo_fondos=(runif(clientes,0.1,0.9)*(rpois(clientes,1)-1>0))*100000
edad=rpois(clientes,60)
datos_ini<-data.frame(cbind(saldo_vista,saldo_ppi,saldo_fondos,edad))
datos_ini$saldo_ppi=(edad<=68)*datos_ini$saldo_ppi
#Creamos la variable objetivo a partir de un potencial
set.seed(2)
datos_ini$potencial=runif(1,0,1)+
(log(edad)/(log(68))/100) +
runif(1,0,0.001)*(saldo_vista>5000)+
runif(1,0,0.001)*(saldo_fondos>10000)+
runif(1,0,0.007)*(saldo_ppi>10000)-
runif(1,0,0.2)
datos_ini$pvi=as.factor((datos_ini$potencial>=quantile(datos_ini$potencial, 0.90))*1)
pred=cbind(datos_ini$saldo_vista,datos_ini$saldo_ppi,
datos_ini$saldo_fondos,datos_ini$edad)
head(pred)
target=as.matrix(datos_ini$pvi)
select=sample(1:clientes,clientes*0.9)
library(nnet)
set.seed(10)
redn=nnet(pred[select,],as.numeric(target[select,]), size = 2,
rang =0.1,decay = 5e-4, maxit = 500)
prediccion=predict(redn, datos_ini)
names(prediccion)=c("prediccion")
datos_ini.pred=cbind(datos_ini,prediccion)
View(datos_ini.pred)
summary(datos_ini.pred)
datos_ini.test = datos_ini.pred[-select,]
View(datos_ini.test)
select
library(png)
library(grDevices)
setwd("D:/FJRA/MASTER_UIC/06RedNeur/Practicas/datos_hopfield\\")
source("hopfield.R")
weights = matrix(c(0, -1, 1, 1,-1, 0, -1, -1, 1, -1, 0, 1, 1, -1, 1, 0), 4, 4)
weights
hopnet = list(weights = weights)
hopnet
init.y = c(-1, -1, -1, -1)
run.hopfield(hopnet, init.y, maxit = 100, stepbystep=F, topo=c(4,1))
run.hopfield(hopnet, init.y, maxit = 1, stepbystep=F, topo=c(4,1))
run.hopfield(hopnet, init.y, maxit = 10, stepbystep=F, topo=c(4,1))
run.hopfield(hopnet, init.y, maxit = 1000, stepbystep=F, topo=c(4,1))
init.y = c(-1, -1, -1, 1)
run.hopfield(hopnet, init.y, maxit = 1000, stepbystep=F, topo=c(4,1))
run.hopfield(hopnet, init.y, maxit = 100, stepbystep=F, topo=c(4,1))
run.hopfield(hopnet, init.y, maxit = 101, stepbystep=F, topo=c(4,1))
run.hopfield(hopnet, init.y, maxit = 103, stepbystep=F, topo=c(4,1))
init.y = c(-1, -1, -1, -1)
for (i in 1:20){
run.hopfield(hopnet, init.y, maxit = 100, stepbystep=F, topo=c(4,1))
}
for (i in 1:20){
print(run.hopfield(hopnet, init.y, maxit = 100, stepbystep=F, topo=c(4,1)))
}
init.y = c(-1, 1, -1, -1)
for (i in 1:20){
print(run.hopfield(hopnet, init.y, maxit = 100, stepbystep=F, topo=c(4,1)))
}
init.y = c(-1, -1, 1, -1)
for (i in 1:20){
print(run.hopfield(hopnet, init.y, maxit = 100, stepbystep=F, topo=c(4,1)))
}
init.y = c(-1, -1, 1, 1) #Inestable
for (i in 1:20){
print(run.hopfield(hopnet, init.y, maxit = 100, stepbystep=F, topo=c(4,1)))
}
init.y = c(1, -1, 1, 1)
for (i in 1:20){
print(run.hopfield(hopnet, init.y, maxit = 100, stepbystep=F, topo=c(4,1)))
}
init.y = c(1, 1, 1, 1)
for (i in 1:20){
print(run.hopfield(hopnet, init.y, maxit = 100, stepbystep=F, topo=c(4,1)))
}
D <- matrix(c(1,-1,-1,-1,-1,1,1,1,1,1,1,-1,-1,-1,1,1,-1,-1,-1,1,-1,1,1,1,-1), nrow=5,ncol = 5)
J <- matrix(c(1,-1,-1,1,1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,1,1,1,-1,1,-1,-1,-1,-1),nrow = 5,ncol = 5)
C <- matrix(c(-1,1,1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,-1,-1,1),nrow = 5,ncol = 5)
M <- matrix(c(1,1,1,1,1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,1,1,1,1,1),nrow = 5,ncol = 5)
##Function to draw the letter
show.letter <- function(letter.vector){
letter.vector[letter.vector == 1] <- "*"
letter.vector[letter.vector == -1] <- " "
colnames(letter.vector) <- rep("",5)
row.names(letter.vector) <- rep("",5)
print(letter.vector, quote = FALSE)
}
for (i in mget(ls(pattern = "^[A-Z]"))){show.letter(i)}
i
mget(ls(pattern = "^[A-Z]"))
##Build letter space
D <- matrix(c(1,-1,-1,-1,-1,1,1,1,1,1,1,-1,-1,-1,1,1,-1,-1,-1,1,-1,1,1,1,-1), nrow=5,ncol = 5)
J <- matrix(c(1,-1,-1,1,1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,1,1,1,-1,1,-1,-1,-1,-1),nrow = 5,ncol = 5)
C <- matrix(c(-1,1,1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,-1,-1,1),nrow = 5,ncol = 5)
M <- matrix(c(1,1,1,1,1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,1,1,1,1,1),nrow = 5,ncol = 5)
##Function to draw the letter
show.letter <- function(letter.vector){
letter.vector[letter.vector == 1] <- "*"
letter.vector[letter.vector == -1] <- " "
colnames(letter.vector) <- rep("",5)
row.names(letter.vector) <- rep("",5)
print(letter.vector, quote = FALSE)
}
for (i in mget(ls(pattern = "^[A-Z]"))){show.letter(i)}
mutate <- function(letter.vector, number.pixel.flips){
letter.vector[sample(length(letter.vector),number.pixel.flips)] <- letter.vector[sample(length(letter.vector),number.pixel.flips)]
return(letter.vector)
}
mutated.C <- mutate(C, 8)
mutated.D <- mutate(D, 8)
mutated.J <- mutate(J, 8)
mutated.M <- mutate(M, 8)
for (i in mget(ls(pattern = "mutated"))){show.letter(i)}
x <- matrix(c(C,D,J,M), nrow = 4, byrow = T)
hopfield <- function(current.letter, iteration, memory = w){
w <- t(x) %*% x
diag(w) <- 0
for(i in 1:iteration){
a <- w %*% as.vector(current.letter)
current.letter <- ifelse(a>0, 1, -1)
}
return(show.letter(matrix(current.letter, ncol = 5, nrow = 5)))
}
for (i in mget(ls(pattern = "mutated"))){
for (iter in 1:5){
hopfield(current.letter = i, iteration = iter)
}
}
